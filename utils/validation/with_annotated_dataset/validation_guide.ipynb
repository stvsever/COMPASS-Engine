{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f1c2d3",
      "metadata": {},
      "source": [
        "# COMPASS — Clinical Validation with Annotated Datasets\n",
        "\n",
        "**Purpose:** This notebook explains how to evaluate COMPASS predictions against annotated ground-truth labels/values from phenotype cohorts.\n",
        "\n",
        "It covers the two validation scripts:\n",
        "1. `compute_confusion_matrix.py` — Mode-aware metric outputs (binary/multiclass/regression/hierarchical)\n",
        "2. `detailed_analysis.py` — Deep statistical analysis (`.txt` + multiple `.png` plots)\n",
        "\n",
        "> These scripts are designed for post-hoc evaluation after a batch run (Step 05) has completed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e2d3f4",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "1. **Completed batch run** — Participant result folders in a `participant_runs/` directory\n",
        "2. **Ground-truth annotations file** — e.g., `cases_controls_with_specific_subtypes.txt`\n",
        "3. **Python dependencies**: `matplotlib`, `numpy`, `scipy` (optional, for statistical tests)\n",
        "\n",
        "Each participant folder should contain at minimum a `report_ID{eid}.json` file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f3e4a5",
      "metadata": {},
      "source": [
        "## File Structure\n",
        "\n",
        "```\n",
        "utils/validation/with_annotated_dataset/\n",
        "├── compute_confusion_matrix.py   # Task-type metric generator\n",
        "├── detailed_analysis.py          # Deep statistical analysis + plots\n",
        "└── validation_guide.ipynb        # This notebook\n",
        "```\n",
        "\n",
        "Output directory structure:\n",
        "```\n",
        "results/analysis/\n",
        "├── binary_confusion_matrix/\n",
        "│   ├── integrated_confusion_matrix.png\n",
        "│   ├── major_depressive_disorder_confusion_matrix.png\n",
        "│   └── ...\n",
        "└── details/\n",
        "    ├── detailed_analysis.txt\n",
        "    ├── composite_vs_accuracy.png\n",
        "    ├── probability_calibration.png\n",
        "    ├── iteration_improvement.png\n",
        "    ├── verdict_accuracy.png\n",
        "    └── ...  (per-disorder variants)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3a4b5c6",
      "metadata": {},
      "source": [
        "## 1. Computing Metrics by Prediction Type\n",
        "\n",
        "The metrics script supports binary, multiclass, regression, and hierarchical evaluation. Binary mode still generates CASE vs CONTROL confusion matrix plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b5c6d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Integrated confusion matrix (all disorders combined) ---\n",
        "# Adjust paths to match your environment.\n",
        "\n",
        "!python utils/validation/with_annotated_dataset/compute_confusion_matrix.py \\\n",
        "    --results_dir ../results/participant_runs \\\n",
        "    --targets_file ../data/__TARGETS__/cases_controls_with_specific_subtypes.txt \\\n",
        "    --prediction_type binary \\\n",
        "    --output_dir ../results/analysis/binary_confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5c6d7e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- With per-disorder breakdown ---\n",
        "# Generates one additional .png per disorder group.\n",
        "\n",
        "!python utils/validation/with_annotated_dataset/compute_confusion_matrix.py \\\n",
        "    --results_dir ../results/participant_runs \\\n",
        "    --targets_file ../data/__TARGETS__/cases_controls_with_specific_subtypes.txt \\\n",
        "    --prediction_type binary \\\n",
        "    --output_dir ../results/analysis/binary_confusion_matrix \\\n",
        "    --disorder_groups \"MAJOR_DEPRESSIVE_DISORDER,ANXIETY_DISORDERS,SUBSTANCE_USE_DISORDERS,SLEEP_WAKE_DISORDERS,BIPOLAR_AND_MANIC_DISORDERS\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6d7e8f9",
      "metadata": {},
      "source": [
        "### Arguments Reference\n",
        "\n",
        "| Argument | Required | Description |\n",
        "|---|---|---|\n",
        "| `--results_dir` | ✓ | Path to directory containing `participant_ID{eid}/` folders |\n",
        "| `--targets_file` | ✓ (binary mode) | Path to annotated ground-truth `.txt` file |\n",
        "| `--prediction_type` | ✗ | `binary` (default), `multiclass`, `regression_univariate`, `regression_multivariate`, `hierarchical` |\n",
        "| `--annotations_json` | ✓ (non-binary) | JSON annotations for multiclass/regression/hierarchical runs |\n",
        "| `--output_dir` | ✓ | Where to save `.png` output files |\n",
        "| `--disorder_groups` | ✗ | Comma-separated list of disorder group names for per-group matrices |\n",
        "\n",
        "### Metrics Displayed\n",
        "\n",
        "In binary mode, each confusion matrix `.png` includes a sidebar with:\n",
        "- **Accuracy** — Overall correct predictions / total\n",
        "- **Sensitivity (Recall)** — TP / (TP + FN) — how well CASEs are detected\n",
        "- **Specificity** — TN / (TN + FP) — how well CONTROLs are identified\n",
        "- **Precision** — TP / (TP + FP) — positive predictive value\n",
        "- **F1 Score** — Harmonic mean of precision and sensitivity\n",
        "- **MCC** — Matthews Correlation Coefficient (balanced metric, range -1 to +1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e8f9a0",
      "metadata": {},
      "source": [
        "## 2. Detailed Statistical Analysis\n",
        "\n",
        "The detailed analysis script generates a comprehensive text report and four diagnostic plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f9a0b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Integrated analysis ---\n",
        "\n",
        "!python utils/validation/with_annotated_dataset/detailed_analysis.py \\\n",
        "    --results_dir ../results/participant_runs \\\n",
        "    --targets_file ../data/__TARGETS__/cases_controls_with_specific_subtypes.txt \\\n",
        "    --prediction_type binary \\\n",
        "    --output_dir ../results/analysis/details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a0b1c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- With per-disorder breakdown ---\n",
        "\n",
        "!python utils/validation/with_annotated_dataset/detailed_analysis.py \\\n",
        "    --results_dir ../results/participant_runs \\\n",
        "    --targets_file ../data/__TARGETS__/cases_controls_with_specific_subtypes.txt \\\n",
        "    --prediction_type binary \\\n",
        "    --output_dir ../results/analysis/details \\\n",
        "    --disorder_groups \"MAJOR_DEPRESSIVE_DISORDER,ANXIETY_DISORDERS,SUBSTANCE_USE_DISORDERS,SLEEP_WAKE_DISORDERS,BIPOLAR_AND_MANIC_DISORDERS\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b1c2d3",
      "metadata": {},
      "source": [
        "### Generated Outputs\n",
        "\n",
        "**Text Report** (`detailed_analysis.txt`):\n",
        "1. Cohort summary (N, cases/controls, failures)\n",
        "2. Task-type metric tables (binary/multiclass/regression/hierarchical)\n",
        "3. Per-disorder breakdown\n",
        "4. Failure analysis\n",
        "5. Verdict quality analysis\n",
        "6. Composite score ↔ accuracy correlation (point-biserial r)\n",
        "7. Probability calibration statistics\n",
        "8. Iteration improvement analysis with significance testing\n",
        "9. Resource usage summary (tokens, duration)\n",
        "10. Full per-participant results table\n",
        "\n",
        "**Plots:**\n",
        "\n",
        "| Plot | What It Shows |\n",
        "|---|---|\n",
        "| `composite_vs_accuracy.png` | Scatter: Critic composite score vs. correct/incorrect (with point-biserial correlation) |\n",
        "| `probability_calibration.png` | Calibration curve + probability histogram (correct vs incorrect) |\n",
        "| `iteration_improvement.png` | Violin + scatter plot of composite scores across iterations, with Mann-Whitney U significance brackets |\n",
        "| `verdict_accuracy.png` | Bar chart: SATISFACTORY vs UNSATISFACTORY verdict accuracy rates |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c2d3e4",
      "metadata": {},
      "source": [
        "## 3. Interpreting Results\n",
        "\n",
        "### Composite Score ↔ Accuracy Correlation\n",
        "If the Critic composite score is working as intended, higher composite scores should correlate with correct predictions. A significant positive point-biserial correlation (`p < 0.05`) confirms this.\n",
        "\n",
        "### Iteration Improvement\n",
        "The violin plot shows whether the actor-critic feedback loop improves prediction quality across iterations. Significance brackets (Mann-Whitney U) annotate whether the improvement is statistically significant:\n",
        "- `***` p < 0.001\n",
        "- `**`  p < 0.01\n",
        "- `*`   p < 0.05\n",
        "- `ns`  not significant\n",
        "\n",
        "### Probability Calibration (Binary)\n",
        "Well-calibrated predictions mean that when the model says 80% probability of CASE, approximately 80% of those predictions should actually be CASEs. The calibration curve deviating from the diagonal indicates miscalibration.\n",
        "\n",
        "### MCC (Matthews Correlation Coefficient, Binary)\n",
        "MCC is the most balanced metric for binary classification. It ranges from -1 (complete disagreement) to +1 (perfect prediction). MCC > 0.3 is generally considered acceptable, > 0.5 is good.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d3e4f5",
      "metadata": {},
      "source": [
        "## 4. Custom Disorder Groups\n",
        "\n",
        "You can analyze any subset of disorders by passing a custom `--disorder_groups` list. The disorder names must match those in the targets file (e.g., `MAJOR_DEPRESSIVE_DISORDER`, `ANXIETY_DISORDERS`).\n",
        "\n",
        "For the standard UK Biobank demonstration cohort, the five groups are:\n",
        "1. `MAJOR_DEPRESSIVE_DISORDER`\n",
        "2. `ANXIETY_DISORDERS`\n",
        "3. `SUBSTANCE_USE_DISORDERS`\n",
        "4. `SLEEP_WAKE_DISORDERS`\n",
        "5. `BIPOLAR_AND_MANIC_DISORDERS`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "version": "3.10",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
