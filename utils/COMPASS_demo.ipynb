{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# COMPASS Engine: Interactive Demo\n",
                "\n",
                "### Clinical Orchestrated Multi-modal Predictive Agentic Support System\n",
                "\n",
                "Welcome to the **COMPASS** interactive demo. This notebook demonstrates the system's reasoning capabilities using synthetic clinical data.\n",
                "\n",
                "**Objective**: To diagnose complex neuropsychiatric conditions by orchestrating multiple AI agents.\n",
                "\n",
                "**Key Features**:\n",
                "- **Dynamic Phenotype Targeting**: Select a specific diagnosis to investigate.\n",
                "- **Transparent Reasoning**: View the step-by-step thoughts of the Orchestrator, Tools, and Predictor.\n",
                "- **Multi-Agent Collaboration**: Orchestrator (Plan) -> Executor (Do) -> Integrator (Fuse) -> Predictor (Solve)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import json\n",
                "import ipywidgets as widgets\n",
                "from IPython.display import display, Markdown, JSON, clear_output\n",
                "from pathlib import Path\n",
                "import subprocess\n",
                "import time\n",
                "\n",
                "# --- PATH SETUP ---\n",
                "# We are in /utils. Navigate up two levels to project root (INFERENCE_PIPELINE)\n",
                "project_root = Path.cwd().parent.parent\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "print(f\"[*] Project Root: {project_root}\")\n",
                "\n",
                "from multi_agent_system.main import run_compass_pipeline\n",
                "from multi_agent_system.config.settings import get_settings, LLMBackend\n",
                "\n",
                "# Locate Data\n",
                "PSEUDO_DATA_ROOT = project_root / \"multi_agent_system\" / \"data\" / \"pseudo_data\"\n",
                "if not PSEUDO_DATA_ROOT.exists():\n",
                "    # Fallback to main data dir if pseudo_data is missing\n",
                "    PSEUDO_DATA_ROOT = project_root / \"data\" / \"__FEATURES__\" / \"COMPASS_data\"\n",
                "\n",
                "print(f\"‚úÖ COMPASS Engine Loaded. Data Source: {PSEUDO_DATA_ROOT.name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Quick Launch: Web Dashboard\n",
                "\n",
                "Want the full visual experience? Click below to launch the **Live Dashboard** in your browser.\n",
                "This runs the separate UI server (`main.py --ui`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def launch_dashboard(b):\n",
                "    clear_output()\n",
                "    print(\"üöÄ Launching Dashboard on port 5005...\")\n",
                "    print(\"Go to: http://127.0.0.1:5005\")\n",
                "    try:\n",
                "        # Use sys.executable to ensure we use the same python env\n",
                "        main_script = project_root / \"multi_agent_system\" / \"main.py\"\n",
                "        subprocess.Popen([sys.executable, str(main_script), \"--ui\"])\n",
                "    except Exception as e:\n",
                "        print(f\"Error launching: {e}\")\n",
                "\n",
                "btn = widgets.Button(description=\"Launch Web Dashboard\", button_style='info', icon='rocket')\n",
                "btn.on_click(launch_dashboard)\n",
                "display(btn)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üî¨ Interactive Notebook Execution\n",
                "\n",
                "Alternatively, run the analysis directly here in the notebook cells."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Configuration\n",
                "Select a subject and your target condition."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find available subjects\n",
                "subjects = [d.name for d in PSEUDO_DATA_ROOT.iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
                "subjects.sort()\n",
                "\n",
                "# Interactive Widgets\n",
                "subject_dropdown = widgets.Dropdown(\n",
                "    options=subjects,\n",
                "    description='Subject:',\n",
                ")\n",
                "\n",
                "target_input = widgets.Text(\n",
                "    value='Major Depressive Disorder',\n",
                "    description='Target Pattern:',\n",
                "    placeholder='e.g. Anxiety'\n",
                ")\n",
                "\n",
                "# Backend Selection\n",
                "backend_dropdown = widgets.Dropdown(\n",
                "    options=[('OpenAI API (GPT-5)', 'openai'), ('Local LLM (Open Source)', 'local')],\n",
                "    value='openai',\n",
                "    description='Backend:',\n",
                ")\n",
                "\n",
                "model_input = widgets.Text(\n",
                "    value='Qwen/Qwen2.5-0.5B-Instruct',\n",
                "    description='Local Model:',\n",
                "    disabled=True\n",
                ")\n",
                "\n",
                "def on_backend_change(change):\n",
                "    if change['new'] == 'local':\n",
                "        model_input.disabled = False\n",
                "    else:\n",
                "        model_input.disabled = True\n",
                "\n",
                "backend_dropdown.observe(on_backend_change, names='value')\n",
                "\n",
                "display(subject_dropdown, target_input, backend_dropdown, model_input)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Run Analysis\n",
                "This executes the pipeline. Output is verbose to show the agent's reasoning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PARTICIPANT_DIR = PSEUDO_DATA_ROOT / subject_dropdown.value\n",
                "TARGET = target_input.value\n",
                "\n",
                "print(f\"Selected Participant: {PARTICIPANT_DIR}\")\n",
                "\n",
                "# Apply Backend Settings\n",
                "settings = get_settings()\n",
                "if backend_dropdown.value == 'local':\n",
                "    settings.models.backend = LLMBackend.LOCAL\n",
                "    settings.models.local_model_name = model_input.value\n",
                "    print(f\"‚öôÔ∏è Configured for LOCAL inference using {model_input.value}\")\n",
                "else:\n",
                "    settings.models.backend = LLMBackend.OPENAI\n",
                "    print(\"‚öôÔ∏è Configured for OPENAI inference\")\n",
                "\n",
                "print(f\"üöÄ STARTING ANALYSIS for: {TARGET}...\")\n",
                "\n",
                "# Run Pipeline\n",
                "try:\n",
                "    result = run_compass_pipeline(\n",
                "        participant_dir=PARTICIPANT_DIR,\n",
                "        target_condition=TARGET,\n",
                "        max_iterations=2,\n",
                "        verbose=True,\n",
                "        interactive_ui=False # Use CLI output mode for notebook compatibility\n",
                "    )\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Execution Error: {e}\")\n",
                "    result = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Inspector\n",
                "View the structured results and decision trace."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if result:\n",
                "    log_path = Path(result['output_dir']) / f\"execution_log_{result['participant_id']}.json\"\n",
                "    report_path = Path(result['output_dir']) / f\"report_{result['participant_id']}.md\"\n",
                "\n",
                "    print(f\"\\nüìä RESULT: {result['prediction']} ({result['probability']:.1%})\")\n",
                "    \n",
                "    if report_path.exists():\n",
                "        display(Markdown(\"### Final Clinical Report\"))\n",
                "        with open(report_path, 'r') as f:\n",
                "            display(Markdown(f.read()))\n",
                "else:\n",
                "    print(\"No successful result to inspect.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}