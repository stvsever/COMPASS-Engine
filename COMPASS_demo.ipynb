{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPASS Engine: Interactive Demo\n",
    "\n",
    "## Clinical Ontology-driven Multi-modal Predictive Agentic Support System\n",
    "\n",
    "This notebook shows how to run COMPASS on a participant folder and inspect outputs.\n",
    "\n",
    "What you'll do:\n",
    "- Optionally launch the web dashboard\n",
    "- Run the pipeline in-notebook (CLI mode)\n",
    "- Inspect the final reports (standard + deep phenotyping)\n",
    "\n",
    "Prerequisites:\n",
    "- Data under `data/pseudo_data` (demo) or `data/__FEATURES__/COMPASS_data`\n",
    "- If using OpenAI, set `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T00:04:51.152413Z",
     "start_time": "2026-02-07T00:04:49.808400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Repo Root: /Users/stijnvanseveren/PythonProjects/IIS_BIOBIZKAIA/INFERENCE_PIPELINE/multi_agent_system\n",
      "[OK] COMPASS Engine Loaded. Data Source: /Users/stijnvanseveren/PythonProjects/IIS_BIOBIZKAIA/INFERENCE_PIPELINE/multi_agent_system/data/pseudo_data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, JSON, clear_output\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for path in [start] + list(start.parents):\n",
    "        if (path / \"main.py\").exists() and (path / \"agents\").exists():\n",
    "            return path\n",
    "    return start\n",
    "\n",
    "\n",
    "repo_root = find_repo_root(Path.cwd())\n",
    "if str(repo_root.parent) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root.parent))\n",
    "\n",
    "print(f\"[*] Repo Root: {repo_root}\")\n",
    "\n",
    "from multi_agent_system.main import run_compass_pipeline\n",
    "from multi_agent_system.config.settings import get_settings, LLMBackend\n",
    "\n",
    "PSEUDO_DATA_ROOT = repo_root / \"data\" / \"pseudo_data\"\n",
    "if not PSEUDO_DATA_ROOT.exists():\n",
    "    PSEUDO_DATA_ROOT = repo_root / \"data\" / \"__FEATURES__\" / \"COMPASS_data\"\n",
    "\n",
    "print(f\"[OK] COMPASS Engine Loaded. Data Source: {PSEUDO_DATA_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Launch: Web Dashboard\n",
    "\n",
    "Launch the live UI (`main.py --ui`) for step-by-step monitoring in your browser.\n",
    "This uses the same Python environment as the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T00:05:12.340934Z",
     "start_time": "2026-02-07T00:05:12.331090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Button(button_style='info', description='Launch Web Dashboard', icon='play', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10716046b47942f1a5cec03dd539a203"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def launch_dashboard(b):\n",
    "    clear_output()\n",
    "    print(\"Launching dashboard on port 5005...\")\n",
    "    print(\"Open: http://127.0.0.1:5005\")\n",
    "    try:\n",
    "        main_script = repo_root / \"main.py\"\n",
    "        subprocess.Popen([sys.executable, str(main_script), \"--ui\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error launching: {e}\")\n",
    "\n",
    "btn = widgets.Button(description=\"Launch Web Dashboard\", button_style='info', icon='play')\n",
    "btn.on_click(launch_dashboard)\n",
    "display(btn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Notebook Execution\n",
    "\n",
    "Run the pipeline directly in the notebook (CLI mode).\n",
    "This is useful for quick iteration and debugging without the web dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration\n",
    "Select a subject, target condition, control comparator, backend, and number of iterations.\n",
    "If you choose the Local backend, ensure the model is available on this machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available subjects\n",
    "subjects = [d.name for d in PSEUDO_DATA_ROOT.iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
    "subjects.sort()\n",
    "\n",
    "# Interactive Widgets\n",
    "subject_dropdown = widgets.Dropdown(\n",
    "    options=subjects,\n",
    "    description='Subject:',\n",
    ")\n",
    "\n",
    "target_input = widgets.Text(\n",
    "    value='Major Depressive Disorder',\n",
    "    description='Target:',\n",
    "    placeholder='e.g. Anxiety'\n",
    ")\n",
    "\n",
    "control_input = widgets.Text(\n",
    "    value='brain-implicated pathology, but NOT psychiatric',\n",
    "    description='Control:',\n",
    "    placeholder='e.g. brain-implicated pathology, but NOT psychiatric'\n",
    ")\n",
    "\n",
    "iterations_input = widgets.BoundedIntText(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=5,\n",
    "    description='Iterations:',\n",
    ")\n",
    "\n",
    "# Backend Selection\n",
    "backend_dropdown = widgets.Dropdown(\n",
    "    options=[('OpenAI API (gpt-5-nano)', 'openai'), ('Local LLM (vLLM/Transformers)', 'local')],\n",
    "    value='openai',\n",
    "    description='Backend:',\n",
    ")\n",
    "\n",
    "model_input = widgets.Text(\n",
    "    value='Qwen/Qwen2.5-0.5B-Instruct',\n",
    "    description='Local Model:',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "\n",
    "def on_backend_change(change):\n",
    "    if change['new'] == 'local':\n",
    "        model_input.disabled = False\n",
    "    else:\n",
    "        model_input.disabled = True\n",
    "\n",
    "\n",
    "backend_dropdown.observe(on_backend_change, names='value')\n",
    "\n",
    "display(subject_dropdown, target_input, control_input, iterations_input, backend_dropdown, model_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run Analysis\n",
    "This executes the pipeline and prints verbose output so you can follow agent reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANT_DIR = PSEUDO_DATA_ROOT / subject_dropdown.value\n",
    "TARGET = target_input.value\n",
    "CONTROL = control_input.value\n",
    "MAX_ITERS = iterations_input.value\n",
    "\n",
    "print(f\"Selected Participant: {PARTICIPANT_DIR}\")\n",
    "\n",
    "# Apply Backend Settings\n",
    "settings = get_settings()\n",
    "if backend_dropdown.value == 'local':\n",
    "    settings.models.backend = LLMBackend.LOCAL\n",
    "    settings.models.local_model_name = model_input.value\n",
    "    print(f\"Configured for LOCAL inference using {model_input.value}\")\n",
    "else:\n",
    "    settings.models.backend = LLMBackend.OPENAI\n",
    "    for attr in [\n",
    "        'orchestrator_model', 'critic_model', 'predictor_model',\n",
    "        'integrator_model', 'communicator_model', 'tool_model'\n",
    "    ]:\n",
    "        setattr(settings.models, attr, 'gpt-5-nano')\n",
    "    print(\"Configured for OPENAI inference (gpt-5-nano for all agents)\")\n",
    "\n",
    "print(f\"Starting analysis for: {TARGET}\")\n",
    "print(f\"Control comparator: {CONTROL}\")\n",
    "\n",
    "# Run Pipeline\n",
    "try:\n",
    "    result = run_compass_pipeline(\n",
    "        participant_dir=PARTICIPANT_DIR,\n",
    "        target_condition=TARGET,\n",
    "        control_condition=CONTROL,\n",
    "        max_iterations=MAX_ITERS,\n",
    "        verbose=True,\n",
    "        interactive_ui=False  # Use CLI output mode for notebook compatibility\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Execution Error: {e}\")\n",
    "    result = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inspector\n",
    "Review the final standard report, the deep phenotyping report, and the structured execution log generated by the run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    log_path = Path(result['output_dir']) / f\"execution_log_{result['participant_id']}.json\"\n",
    "    report_path = Path(result['output_dir']) / f\"report_{result['participant_id']}.md\"\n",
    "    deep_path = Path(result['output_dir']) / \"deep_phenotype.md\"\n",
    "\n",
    "    print(f\"RESULT: {result['prediction']} ({result['probability']:.1%})\")\n",
    "\n",
    "    if report_path.exists():\n",
    "        display(Markdown(\"### Final Clinical Report\"))\n",
    "        with open(report_path, 'r') as f:\n",
    "            display(Markdown(f.read()))\n",
    "\n",
    "    if deep_path.exists():\n",
    "        display(Markdown(\"### Deep Phenotyping Report\"))\n",
    "        with open(deep_path, 'r') as f:\n",
    "            display(Markdown(f.read()))\n",
    "\n",
    "    if log_path.exists():\n",
    "        display(Markdown(\"### Execution Log\"))\n",
    "        with open(log_path, 'r') as f:\n",
    "            display(JSON(json.load(f), expanded=False))\n",
    "else:\n",
    "    print(\"No successful result to inspect.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
